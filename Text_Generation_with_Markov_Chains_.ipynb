{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "V28"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Importing Necessary Libraries\n",
        "\n",
        "re: This module provides support for regular expressions, which are used for searching and manipulating strings.\n",
        "\n",
        "random: This module implements pseudo-random number generators for various distributions.\n",
        "\n",
        "defaultdict from collections: This class is a subclass of the built-in dict class. It overrides one method and adds one writable instance variable. The functionality of the dictionary is extended to provide a default value for the key that does not exist."
      ],
      "metadata": {
        "id": "njQtYjU_C-PV"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "tRyY8XG0CzOM"
      },
      "outputs": [],
      "source": [
        "import re\n",
        "import random\n",
        "from collections import defaultdict\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This is a sample text used to train the Markov chain model. The corpus is a string containing multiple sentences.\n"
      ],
      "metadata": {
        "id": "nUeKIz3ADikF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "corpus = \"\"\"\n",
        "In a village of La Mancha, the name of which I have no desire to call to mind, there lived not long since one of those gentlemen that keep a lance in the lance-rack, an old buckler, a lean hack, and a greyhound for coursing.\n",
        "An olla of rather more beef than mutton, a salad on most nights, scraps on Saturdays, lentils on Fridays, and a pigeon or so extra on Sundays, made away with three-quarters of his income.\n",
        "\"\"\"\n"
      ],
      "metadata": {
        "id": "5ktxCXxFC5GG"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Tokenize the Text\n",
        "\n",
        "\n",
        "The tokenize function processes the input text to prepare it for the Markov chain model.\n",
        "\n",
        "text.lower(): Converts all characters in the text to lowercase to ensure uniformity.\n",
        "\n",
        "re.findall (r'\\b\\w+\\b', text): Uses a regular expression to find all words in the text. The pattern \\b\\w+\\b matches word boundaries around sequences of word characters (letters, digits, and underscores).\n",
        "\n",
        "The result is a list of words (tokens) extracted from the corpus.\n",
        "\n"
      ],
      "metadata": {
        "id": "0U4HTjNlDqYM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def tokenize(text):\n",
        "    text = text.lower()  # Convert to lowercase\n",
        "    words = re.findall(r'\\b\\w+\\b', text)  # Find all words\n",
        "    return words\n",
        "\n",
        "tokens = tokenize(corpus)\n"
      ],
      "metadata": {
        "id": "_v8_gWVlDpiK"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Build the Markov Chain Model\n",
        "\n",
        "The build_markov_chain function constructs the Markov chain model.\n",
        "\n",
        "defaultdict(list): Creates a dictionary where each key has a default value of an empty list. This is used to store the list of possible next words for each key.\n",
        "\n",
        "The function iterates through the list of tokens to build the Markov chain:\n",
        "\n",
        "key = tuple(tokens[i:i+n]): Creates a tuple of n consecutive words from the tokens list. This tuple serves as the key in the Markov chain.\n",
        "\n",
        "next_word = tokens[i+n]: Identifies the word following the key.\n",
        "\n",
        "markov_chain[key].append(next_word): Adds the next word to the list of possible subsequent words for the given key.\n",
        "\n",
        "The function returns the constructed Markov chain."
      ],
      "metadata": {
        "id": "2P0aY8sID9n8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def build_markov_chain(tokens, n=1):\n",
        "    markov_chain = defaultdict(list)\n",
        "    for i in range(len(tokens) - n):\n",
        "        key = tuple(tokens[i:i+n])\n",
        "        next_word = tokens[i+n]\n",
        "        markov_chain[key].append(next_word)\n",
        "    return markov_chain\n",
        "\n",
        "markov_chain = build_markov_chain(tokens, n=1)\n"
      ],
      "metadata": {
        "id": "55JN9Pa_DscT"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Generate Text\n",
        "\n",
        "The generate_text function generates a sequence of words using the Markov chain model.\n",
        "\n",
        "\n",
        "start = random.choice(list(markov_chain.keys())): Randomly selects a starting key from the Markov chain.\n",
        "\n",
        "current_words = list(start): Initializes the list of current words with the starting key.\n",
        "\n",
        "text = current_words[:]: Initializes the generated text with the current words.\n",
        "\n",
        "The function iterates to generate the specified number of words (length):\n",
        "\n",
        "  key = tuple(current_words[-n:]): Extracts the last n words from the current words to form the key.\n",
        "\n",
        "  next_word = random.choice(markov_chain[key]): Randomly selects the next word from the list of possible subsequent words for the current key.\n",
        "\n",
        "  text.append(next_word): Adds the next word to the generated text.\n",
        "\n",
        "  current_words.append(next_word): Adds the next word to the list of current words.\n",
        "\n",
        "The function returns the generated text as a single string."
      ],
      "metadata": {
        "id": "v4RIauWsEQni"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_text(markov_chain, length=50, n=1):\n",
        "    start = random.choice(list(markov_chain.keys()))\n",
        "    current_words = list(start)\n",
        "    text = current_words[:]\n",
        "\n",
        "    for _ in range(length - n):\n",
        "        key = tuple(current_words[-n:])\n",
        "        next_word = random.choice(markov_chain[key])\n",
        "        text.append(next_word)\n",
        "        current_words.append(next_word)\n",
        "\n",
        "    return ' '.join(text)\n",
        "\n",
        "generated_text = generate_text(markov_chain, length=50, n=1)\n",
        "print(generated_text)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fx6YliPlEN5g",
        "outputId": "86071cf8-4693-48e4-fdda-c2da9e2849ae"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "those gentlemen that keep a greyhound for coursing an old buckler a village of which i have no desire to mind there lived not long since one of which i have no desire to mind there lived not long since one of rather more beef than mutton a lance rack\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "FmWOy0DCEjtQ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}